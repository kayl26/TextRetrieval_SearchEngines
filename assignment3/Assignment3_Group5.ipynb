{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p558KlVfdazZ"
      },
      "source": [
        "# CP423: Assignment 3\n",
        "\n",
        "Group Number: 5\n",
        "\n",
        "Group Members: Abigail Lee (200469770), Kayleigh Habib (200370580) and Myisha Chaudhry (200591740)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dk0uPGI8dazb"
      },
      "outputs": [],
      "source": [
        "# MIGHT NEED TO RUN THIS FOR THE NLTK\n",
        "#pip install certifi\n",
        "# MIGHT NEED TO RUN THIS FOR reading file\n",
        "# pip install lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PXaijh1edazc"
      },
      "outputs": [],
      "source": [
        "import certifi\n",
        "import ssl\n",
        "import os\n",
        "\n",
        "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VebyIJDydazc"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj_YXbA-dazc"
      },
      "source": [
        "# Question 1 : Introduction to Webscraping\n",
        "\n",
        "Your task involves working with the given URL, which pertains to historical population counts of various Canadian provinces as recorded on Wikipedia\n",
        "(https://en.wikipedia.org/wiki/List_of_Canadian_provinces_and_territories_by_historical_population).\n",
        "\n",
        "Your goal in this segment is to import HTML tables from the web and manipulate them using pandas.\n",
        "\n",
        "\n",
        "Here's a breakdown of what you will do:\n",
        "\n",
        "1. Retrieve the specified webpage as raw HTML using the requests library\n",
        "\n",
        "2. Decode the HTML into a tree-structured Python object with the BeautifulSoup library\n",
        "\n",
        "3. Utilize BeautifulSoup to identify and extract only the tables we're interested in\n",
        "\n",
        "4. Merge the tables, sanitize the text, and transform them into a single Python dictionary\n",
        "\n",
        "5. Construct a pandas dataframe out of this dictionary\n",
        "\n",
        "6. Locate all h2 elements on the HTML page and display their text content\n",
        "\n",
        "7. Generate a list of all the hyperlinks embedded within the tables\n",
        "\n",
        "8. Download every webpage by traversing the links included in the list created in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "mG18yjV1dazc",
        "outputId": "d579d8e7-968a-470f-8d08-62a7c5e281ea",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Part 1: Retrieve the specified webpage as raw HTML\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_Canadian_provinces_and_territories_by_historical_population\"\n",
        "response = requests.get(url) # retrieve the link\n",
        "raw_html = response.text # get the contents as a string\n",
        "# raw_html "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7sMAYs3adazd"
      },
      "outputs": [],
      "source": [
        "# Part 2: Decode the HTML into a tree-structure object\n",
        "tree_stru = BeautifulSoup(raw_html, features = \"html.parser\") # html.parser converts it to a BeautifulSoup type\n",
        "# tree_stru\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gcs0gc3Rdazd"
      },
      "outputs": [],
      "source": [
        "# Part 3: Identify and extract only tables we are interested in\n",
        "inter_tables = tree_stru.find_all('table',class_='wikitable') # find all tables\n",
        "# inter_tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dYb8l4CWdazd"
      },
      "outputs": [],
      "source": [
        "def sanitize_func(data):\n",
        "    result = \"\"\n",
        "    pattern = \"\\[.+\\]\" # pattern\n",
        "    result = re.sub(pattern,\" \", str(data)).strip() #if the pattern matches replace with empty string and strip any empty string\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eogxnKkAdazd",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "510b02e4-dbda-455c-db05-564885de2974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Name': {0: 'Lower Canada', 1: 'New Brunswick', 2: 'Newfoundland', 3: 'Nova Scotia', 4: 'Prince Edward Island', 5: 'Upper Canada', 6: 'Total', 7: 'Alberta', 8: 'British Columbia', 9: 'Manitoba', 10: 'Newfoundland and Labrador', 11: 'Northwest Territories', 12: 'Nunavut', 13: 'Ontario', 14: 'Quebec', 15: 'Saskatchewan', 16: 'Yukon', 17: 'Canada'}, '1700': {0: '14000.0', 1: 'nan', 2: '500.0', 3: '1300.0', 4: 'nan', 5: 'nan', 6: '15800.0', 7: 'nan', 8: 'nan', 9: 'nan', 10: 'nan', 11: 'nan', 12: 'nan', 13: 'nan', 14: 'nan', 15: 'nan', 16: 'nan', 17: 'nan'}, '1725': {0: '29000.0', 1: 'nan', 2: '5000.0', 3: '5000.0', 4: '300.0', 5: 'nan', 6: '39300.0', 7: 'nan', 8: 'nan', 9: 'nan', 10: 'nan', 11: 'nan', 12: 'nan', 13: 'nan', 14: 'nan', 15: 'nan', 16: 'nan', 17: 'nan'}, '1750': {0: '54500.0', 1: 'nan', 2: '10000.0', 3: '14000.0', 4: '2500.0', 5: 'nan', 6: '81000.0', 7: 'nan', 8: 'nan', 9: 'nan', 10: 'nan', 11: 'nan', 12: 'nan', 13: 'nan', 14: 'nan', 15: 'nan', 16: 'nan', 17: 'nan'}, '1775': {0: '96000.0', 1: 'nan', 2: '16000.0', 3: '20000.0', 4: '10000.0', 5: '8000.0', 6: '150000.0', 7: 'nan', 8: 'nan', 9: 'nan', 10: 'nan', 11: 'nan', 12: 'nan', 13: 'nan', 14: 'nan', 15: 'nan', 16: 'nan', 17: 'nan'}, '1800': {0: '225000', 1: '10000', 2: '10000', 3: '57000', 4: '20000', 5: '50000', 6: '382000', 7: 'nan', 8: 'nan', 9: 'nan', 10: 'nan', 11: 'nan', 12: 'nan', 13: 'nan', 14: 'nan', 15: 'nan', 16: 'nan', 17: 'nan'}, '1825': {0: '450000', 1: '75000', 2: '45759', 3: '150000', 4: '28600', 5: '158027', 6: '907386', 7: 'nan', 8: 'nan', 9: 'nan', 10: 'nan', 11: 'nan', 12: 'nan', 13: 'nan', 14: 'nan', 15: 'nan', 16: 'nan', 17: 'nan'}, 'Confederated': {0: 'nan', 1: '1867.0', 2: 'nan', 3: '1867.0', 4: '1873.0', 5: 'nan', 6: 'nan', 7: '1905.0', 8: '1871.0', 9: '1870.0', 10: '1949.0', 11: '1870.0', 12: '1999.0', 13: '1867.0', 14: '1867.0', 15: '1905.0', 16: '1898.0', 17: 'nan'}, '1841': {0: 'nan', 1: '156,162', 2: 'nan', 3: '202,575', 4: '47042', 5: 'nan', 6: 'nan', 7: 'nan', 8: '62100', 9: '4,704', 10: '96,296', 11: 'nan', 12: 'nan', 13: '466,831', 14: '716,670', 15: 'nan', 16: 'nan', 17: '1752380'}, '1851': {0: 'nan', 1: '193800', 2: 'nan', 3: '276854', 4: '62,678', 5: 'nan', 6: 'nan', 7: 'nan', 8: '55000', 9: '5,391', 10: '101600', 11: '5700', 12: 'nan', 13: '952,004', 14: '890,261', 15: 'nan', 16: 'nan', 17: '2543288'}, '1861': {0: 'nan', 1: '252047', 2: 'nan', 3: '330857', 4: '80857', 5: 'nan', 6: 'nan', 7: 'nan', 8: '51524', 9: '6766', 10: '124,288', 11: '6691', 12: 'nan', 13: '1,396,091', 14: '1,111,566', 15: 'nan', 16: 'nan', 17: '3353921'}, '1871': {0: 'nan', 1: '285594', 2: 'nan', 3: '387800', 4: '94021', 5: 'nan', 6: 'nan', 7: '6272', 8: '36247', 9: '25228', 10: '146,536', 11: '48000', 12: 'nan', 13: '1620851', 14: '1191516', 15: '6924', 16: 'nan', 17: '3835793'}, '1881': {0: 'nan', 1: '321233', 2: 'nan', 3: '440572', 4: '108891', 5: 'nan', 6: 'nan', 7: '14720', 8: '49459', 9: '62260', 10: '197,335', 11: '56446', 12: 'nan', 13: '1926922', 14: '1359027', 15: '8804', 16: 'nan', 17: '4522145'}, '1891': {0: 'nan', 1: '321263', 2: 'nan', 3: '450396', 4: '109078', 5: 'nan', 6: 'nan', 7: '25,277', 8: '98173', 9: '152506', 10: '202,040', 11: '62540', 12: 'nan', 13: '2114321', 14: '1488535', 15: '11,150', 16: 'nan', 17: '5035279'}, '1901': {0: 'nan', 1: '331120', 2: 'nan', 3: '459574', 4: '103259', 5: 'nan', 6: 'nan', 7: '73022', 8: '178657', 9: '255211', 10: '220,984', 11: '20129', 12: 'nan', 13: '2182947', 14: '1648898', 15: '91279', 16: '27219', 17: '5592299'}, '1911': {0: 'nan', 1: '351889', 2: 'nan', 3: '492338', 4: '93728', 5: 'nan', 6: 'nan', 7: '374295', 8: '392480', 9: '461394', 10: '242,619', 11: '6507', 12: 'nan', 13: '2527292', 14: '2005776', 15: '492432', 16: '8512', 17: '7449262'}, '1921': {0: 'nan', 1: '387876', 2: 'nan', 3: '523837', 4: '88615', 5: 'nan', 6: 'nan', 7: '588454', 8: '524582', 9: '610118', 10: '263,033', 11: '8143', 12: 'nan', 13: '2933662', 14: '2360510', 15: '757510', 16: '4157', 17: '8787949'}, '1931': {0: 'nan', 1: '408219', 2: 'nan', 3: '512846', 4: '88038', 5: 'nan', 6: 'nan', 7: '731605', 8: '694263', 9: '700139', 10: '289,588', 11: '9316', 12: 'nan', 13: '3431683', 14: '2874662', 15: '921785', 16: '4230', 17: '10666374'}, '1941': {0: 'nan', 1: '457401', 2: 'nan', 3: '577962', 4: '95047', 5: 'nan', 6: 'nan', 7: '796169', 8: '817861', 9: '729744', 10: '316,294', 11: '12028', 12: 'nan', 13: '3787655', 14: '3331882', 15: '895992', 16: '4914', 17: '11,828,474'}, '1951': {0: 'nan', 1: '515697.0', 2: 'nan', 3: '642584.0', 4: '98429.0', 5: 'nan', 6: 'nan', 7: '939501.0', 8: '1165210.0', 9: '776541.0', 10: '361416.0', 11: '16004.0', 12: 'nan', 13: '4597542.0', 14: '4055681.0', 15: '831728.0', 16: '9096.0', 17: '14009429.0'}, '1956': {0: 'nan', 1: '554616.0', 2: 'nan', 3: '694717.0', 4: '99285.0', 5: 'nan', 6: 'nan', 7: '1123116.0', 8: '1398464.0', 9: '850040.0', 10: '415074.0', 11: '19313.0', 12: 'nan', 13: '5404933.0', 14: '4628378.0', 15: '880665.0', 16: '12190.0', 17: '16080791.0'}, '1961': {0: 'nan', 1: '597936.0', 2: 'nan', 3: '737007.0', 4: '104629.0', 5: 'nan', 6: 'nan', 7: '1331944.0', 8: '1629082.0', 9: '921686.0', 10: '457853.0', 11: '22998.0', 12: 'nan', 13: '6236092.0', 14: '5259211.0', 15: '925181.0', 16: '14628.0', 17: '18238247.0'}, '1966': {0: 'nan', 1: '616788.0', 2: 'nan', 3: '756039.0', 4: '108535.0', 5: 'nan', 6: 'nan', 7: '1463203.0', 8: '1873674.0', 9: '963066.0', 10: '493396.0', 11: '28738.0', 12: 'nan', 13: '6960870.0', 14: '5780845.0', 15: '955344.0', 16: '14382.0', 17: '20014880.0'}, '1971': {0: 'nan', 1: '634557.0', 2: 'nan', 3: '788960.0', 4: '111641.0', 5: 'nan', 6: 'nan', 7: '1627874.0', 8: '2184621.0', 9: '988247.0', 10: '522104.0', 11: '34807.0', 12: 'nan', 13: '7703106.0', 14: '6027764.0', 15: '926242.0', 16: '18388.0', 17: '21568311.0'}, '1976': {0: 'nan', 1: '677250.0', 2: 'nan', 3: '828571.0', 4: '118229.0', 5: 'nan', 6: 'nan', 7: '1838037.0', 8: '2466608.0', 9: '1021506.0', 10: '557725.0', 11: '42609.0', 12: 'nan', 13: '8264465.0', 14: '6234445.0', 15: '921323.0', 16: '21836.0', 17: '22992604.0'}, '1981': {0: 'nan', 1: '689375.0', 2: 'nan', 3: '839805.0', 4: '121225.0', 5: 'nan', 6: 'nan', 7: '2213650.0', 8: '2713615.0', 9: '1013705.0', 10: '563750.0', 11: '45540.0', 12: 'nan', 13: '8534265.0', 14: '6369065.0', 15: '956440.0', 16: '23075.0', 17: '24083510.0'}, '1986': {0: 'nan', 1: '709442.0', 2: 'nan', 3: '873176.0', 4: '126646.0', 5: 'nan', 6: 'nan', 7: '2365825.0', 8: '2883367.0', 9: '1063016.0', 10: '568349.0', 11: '52238.0', 12: 'nan', 13: '9101694.0', 14: '6532461.0', 15: '1009613.0', 16: '23504.0', 17: '25309331.0'}, '1991': {0: 'nan', 1: '723900.0', 2: 'nan', 3: '899942.0', 4: '129765.0', 5: 'nan', 6: 'nan', 7: '2545553.0', 8: '3282061.0', 9: '1091942.0', 10: '568474.0', 11: '57649.0', 12: 'nan', 13: '10084885.0', 14: '6895963.0', 15: '988928.0', 16: '27797.0', 17: '27296859.0'}, '1996': {0: 'nan', 1: '738133', 2: 'nan', 3: '909282', 4: '134557', 5: 'nan', 6: 'nan', 7: '2696826', 8: '3724500', 9: '1113898', 10: '551792', 11: '39672', 12: '24730', 13: '10753573', 14: '7138795', 15: '990237', 16: '30766', 17: '28846761'}, '2001': {0: 'nan', 1: '729498', 2: 'nan', 3: '908007', 4: '135294', 5: 'nan', 6: 'nan', 7: '2974807', 8: '3907738', 9: '1119583', 10: '512930', 11: '37360', 12: '26745', 13: '11410046', 14: '7237479', 15: '978933', 16: '28674', 17: '30007094'}, '2006': {0: 'nan', 1: '729997', 2: 'nan', 3: '913462', 4: '135851', 5: 'nan', 6: 'nan', 7: '3290350', 8: '4113487', 9: '1148401', 10: '505469', 11: '41464', 12: '29474', 13: '12160282', 14: '7546131', 15: '968157', 16: '30372', 17: '31612897'}, '2011': {0: 'nan', 1: '751171', 2: 'nan', 3: '921727', 4: '140204', 5: 'nan', 6: 'nan', 7: '3645257', 8: '4400057', 9: '1208268', 10: '514536', 11: '41462', 12: '31906', 13: '12851821', 14: '7903001', 15: '1033381', 16: '33897', 17: '33476688'}, '2016': {0: 'nan', 1: '747101', 2: 'nan', 3: '923598', 4: '142907', 5: 'nan', 6: 'nan', 7: '4067175', 8: '4648055', 9: '1278365', 10: '519716', 11: '41786', 12: '35944', 13: '13448494', 14: '8164361', 15: '1098352', 16: '35874', 17: '35151728'}, '2021': {0: 'nan', 1: '775610', 2: 'nan', 3: '969383', 4: '154331', 5: 'nan', 6: 'nan', 7: '4262635', 8: '5000879', 9: '1342153', 10: '510550', 11: '41070', 12: '36858', 13: '14223942', 14: '8501833', 15: '1132505', 16: '40232', 17: '36991981'}}\n"
          ]
        }
      ],
      "source": [
        "# Part 4: Merge, Sanitize and transform into Python dictionary\n",
        "new_dict = {}\n",
        "final_dict = {}\n",
        "df_mer = pd.DataFrame() # empty merged df\n",
        "index = 1\n",
        "for table in inter_tables: # go through each table\n",
        "    df = pd.read_html(str(table))[0] # read the html as a df of strings\n",
        "    df = df.applymap(sanitize_func) # call the helper function\n",
        "    \n",
        "    # if it is the first occurence put all the data into our dataframe\n",
        "    if index == 1:\n",
        "        df_mer = df\n",
        "    else: # otherwise merge them on the common field\n",
        "        df_mer = df_mer.merge(df, on= 'Name', how = 'outer') #joins the tables on the names\n",
        "    index+=1\n",
        "\n",
        "#create a dictionary\n",
        "new_dict = df_mer.to_dict()\n",
        "# print(new_dict)\n",
        "\n",
        "# go through each element and ensure it is cleaned\n",
        "for key,val in new_dict.items():\n",
        "    # key is the column name\n",
        "    temp_dict = {}\n",
        "    for k,v in val.items():\n",
        "        # key is the index, value is the row\n",
        "        temp_dict[k] = sanitize_func(str(v))\n",
        "\n",
        "    final_dict[sanitize_func(key)] = temp_dict\n",
        "\n",
        "print(final_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "p2bY3aGHdaze",
        "outputId": "a0459570-0bd5-493d-ad87-aa209371e5b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>1700</th>\n",
              "      <th>1725</th>\n",
              "      <th>1750</th>\n",
              "      <th>1775</th>\n",
              "      <th>1800</th>\n",
              "      <th>1825</th>\n",
              "      <th>Confederated</th>\n",
              "      <th>1841</th>\n",
              "      <th>1851</th>\n",
              "      <th>...</th>\n",
              "      <th>1976</th>\n",
              "      <th>1981</th>\n",
              "      <th>1986</th>\n",
              "      <th>1991</th>\n",
              "      <th>1996</th>\n",
              "      <th>2001</th>\n",
              "      <th>2006</th>\n",
              "      <th>2011</th>\n",
              "      <th>2016</th>\n",
              "      <th>2021</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lower Canada</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>29000.0</td>\n",
              "      <td>54500.0</td>\n",
              "      <td>96000.0</td>\n",
              "      <td>225000</td>\n",
              "      <td>450000</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>New Brunswick</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>10000</td>\n",
              "      <td>75000</td>\n",
              "      <td>1867.0</td>\n",
              "      <td>156,162</td>\n",
              "      <td>193800</td>\n",
              "      <td>...</td>\n",
              "      <td>677250.0</td>\n",
              "      <td>689375.0</td>\n",
              "      <td>709442.0</td>\n",
              "      <td>723900.0</td>\n",
              "      <td>738133</td>\n",
              "      <td>729498</td>\n",
              "      <td>729997</td>\n",
              "      <td>751171</td>\n",
              "      <td>747101</td>\n",
              "      <td>775610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Newfoundland</td>\n",
              "      <td>500.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>45759</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nova Scotia</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>57000</td>\n",
              "      <td>150000</td>\n",
              "      <td>1867.0</td>\n",
              "      <td>202,575</td>\n",
              "      <td>276854</td>\n",
              "      <td>...</td>\n",
              "      <td>828571.0</td>\n",
              "      <td>839805.0</td>\n",
              "      <td>873176.0</td>\n",
              "      <td>899942.0</td>\n",
              "      <td>909282</td>\n",
              "      <td>908007</td>\n",
              "      <td>913462</td>\n",
              "      <td>921727</td>\n",
              "      <td>923598</td>\n",
              "      <td>969383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prince Edward Island</td>\n",
              "      <td>nan</td>\n",
              "      <td>300.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>28600</td>\n",
              "      <td>1873.0</td>\n",
              "      <td>47042</td>\n",
              "      <td>62,678</td>\n",
              "      <td>...</td>\n",
              "      <td>118229.0</td>\n",
              "      <td>121225.0</td>\n",
              "      <td>126646.0</td>\n",
              "      <td>129765.0</td>\n",
              "      <td>134557</td>\n",
              "      <td>135294</td>\n",
              "      <td>135851</td>\n",
              "      <td>140204</td>\n",
              "      <td>142907</td>\n",
              "      <td>154331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Name     1700     1725     1750     1775    1800    1825  \\\n",
              "0          Lower Canada  14000.0  29000.0  54500.0  96000.0  225000  450000   \n",
              "1         New Brunswick      nan      nan      nan      nan   10000   75000   \n",
              "2          Newfoundland    500.0   5000.0  10000.0  16000.0   10000   45759   \n",
              "3           Nova Scotia   1300.0   5000.0  14000.0  20000.0   57000  150000   \n",
              "4  Prince Edward Island      nan    300.0   2500.0  10000.0   20000   28600   \n",
              "\n",
              "  Confederated     1841    1851  ...      1976      1981      1986      1991  \\\n",
              "0          nan      nan     nan  ...       nan       nan       nan       nan   \n",
              "1       1867.0  156,162  193800  ...  677250.0  689375.0  709442.0  723900.0   \n",
              "2          nan      nan     nan  ...       nan       nan       nan       nan   \n",
              "3       1867.0  202,575  276854  ...  828571.0  839805.0  873176.0  899942.0   \n",
              "4       1873.0    47042  62,678  ...  118229.0  121225.0  126646.0  129765.0   \n",
              "\n",
              "     1996    2001    2006    2011    2016    2021  \n",
              "0     nan     nan     nan     nan     nan     nan  \n",
              "1  738133  729498  729997  751171  747101  775610  \n",
              "2     nan     nan     nan     nan     nan     nan  \n",
              "3  909282  908007  913462  921727  923598  969383  \n",
              "4  134557  135294  135851  140204  142907  154331  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Part 5: Construct a pandas dataframe\n",
        "pd_df = pd.DataFrame(data = final_dict) # uses the dictionary as our data\n",
        "pd_df.head() # prints first 5 rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su8Nch5ydaze",
        "outputId": "d58d7ef7-598b-4d11-9a6b-c7b06a5fc706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contents\n",
            "1700 to 1825\n",
            "1841 to 1931\n",
            "1941 to 1991\n",
            "1996 to 2021\n",
            "Notes\n"
          ]
        }
      ],
      "source": [
        "# Part 6: Locate h2 elements on the HTML page and display their text content\n",
        "\n",
        "# find the h2 elements on the HTML page\n",
        "h2_elements = tree_stru.find_all(\"h2\")\n",
        "\n",
        "for h2 in h2_elements:\n",
        "\n",
        "    # get the h2 text content\n",
        "    text = (h2.get_text())\n",
        "\n",
        "    # remove the [edit] from the text\n",
        "    text = text.replace('[edit]', '')\n",
        "    print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8BoNVFwYdaze"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://en.wikipedia.org/wiki/Alberta', 'https://en.wikipedia.org/wiki/British_Columbia', 'https://en.wikipedia.org/wiki/Manitoba', 'https://en.wikipedia.org/wiki/New_Brunswick', 'https://en.wikipedia.org/wiki/Newfoundland_and_Labrador', 'https://en.wikipedia.org/wiki/Northwest_Territories', 'https://en.wikipedia.org/wiki/Nova_Scotia', 'https://en.wikipedia.org/wiki/Nunavut', 'https://en.wikipedia.org/wiki/Ontario', 'https://en.wikipedia.org/wiki/Prince_Edward_Island', 'https://en.wikipedia.org/wiki/Quebec', 'https://en.wikipedia.org/wiki/Saskatchewan', 'https://en.wikipedia.org/wiki/Yukon', 'https://en.wikipedia.org/wiki/Canada', 'https://en.wikipedia.org/wiki/Alberta', 'https://en.wikipedia.org/wiki/British_Columbia', 'https://en.wikipedia.org/wiki/Manitoba', 'https://en.wikipedia.org/wiki/New_Brunswick', 'https://en.wikipedia.org/wiki/Newfoundland_and_Labrador', 'https://en.wikipedia.org/wiki/Northwest_Territories', 'https://en.wikipedia.org/wiki/Nova_Scotia', 'https://en.wikipedia.org/wiki/Nunavut', 'https://en.wikipedia.org/wiki/Ontario', 'https://en.wikipedia.org/wiki/Prince_Edward_Island', 'https://en.wikipedia.org/wiki/Quebec', 'https://en.wikipedia.org/wiki/Saskatchewan', 'https://en.wikipedia.org/wiki/Yukon', 'https://en.wikipedia.org/wiki/Canada', 'https://en.wikipedia.org/wiki/Alberta', 'https://en.wikipedia.org/wiki/British_Columbia', 'https://en.wikipedia.org/wiki/Manitoba', 'https://en.wikipedia.org/wiki/New_Brunswick', 'https://en.wikipedia.org/wiki/Newfoundland_and_Labrador', 'https://en.wikipedia.org/wiki/Northwest_Territories', 'https://en.wikipedia.org/wiki/Nova_Scotia', 'https://en.wikipedia.org/wiki/Nunavut', 'https://en.wikipedia.org/wiki/Ontario', 'https://en.wikipedia.org/wiki/Prince_Edward_Island', 'https://en.wikipedia.org/wiki/Quebec', 'https://en.wikipedia.org/wiki/Saskatchewan', 'https://en.wikipedia.org/wiki/Yukon', 'https://en.wikipedia.org/wiki/Canada', 'https://en.wikipedia.org/wiki/Alberta', 'https://en.wikipedia.org/wiki/British_Columbia', 'https://en.wikipedia.org/wiki/Manitoba', 'https://en.wikipedia.org/wiki/New_Brunswick', 'https://en.wikipedia.org/wiki/Newfoundland_and_Labrador', 'https://en.wikipedia.org/wiki/Northwest_Territories', 'https://en.wikipedia.org/wiki/Nova_Scotia', 'https://en.wikipedia.org/wiki/Nunavut', 'https://en.wikipedia.org/wiki/Ontario', 'https://en.wikipedia.org/wiki/Prince_Edward_Island', 'https://en.wikipedia.org/wiki/Quebec', 'https://en.wikipedia.org/wiki/Saskatchewan', 'https://en.wikipedia.org/wiki/Yukon', 'https://en.wikipedia.org/wiki/Canada']\n"
          ]
        }
      ],
      "source": [
        "# Part 7: Generate a list of all hyperlinks embedded within the table\n",
        "\n",
        "hyperlinks = []\n",
        "names = []\n",
        "\n",
        "for hl in inter_tables:\n",
        "\n",
        "    # find all <a> elements in the table (contains the hyperlinks)\n",
        "    links = table.find_all(\"a\")\n",
        "\n",
        "    for link in links:\n",
        "\n",
        "        # get the href attribute of the <a> element which contains the URL of the hyperlink\n",
        "        href = link.get(\"href\")\n",
        "        title = link.get(\"title\")\n",
        "\n",
        "        # check if it is a valid link and is a Wikipedia link\n",
        "        if href and href.startswith('/wiki/'):\n",
        "\n",
        "            # write out the full URL by adding the href element to https://en.wikipedia.org\n",
        "            full_url = f\"https://en.wikipedia.org{href}\"\n",
        "\n",
        "            # add the full URL to the hyperlinks list\n",
        "            hyperlinks.append(full_url)\n",
        "            names.append(title)\n",
        "\n",
        "print(hyperlinks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3THgCmm2daze"
      },
      "outputs": [],
      "source": [
        "# Part 8: Download every webpage by traversing links including in the list created in the previous step.\n",
        "foldername = \"webpages\"\n",
        "\n",
        "# create folder called \"webpages\"\n",
        "os.makedirs(foldername, exist_ok=True)\n",
        "\n",
        "index = 0\n",
        "\n",
        "# loop through hyperlinks from question 7, add content of each page to folder\n",
        "for link in hyperlinks:\n",
        "\n",
        "  # get page content\n",
        "  page = requests.get(link)\n",
        "  webpage = page.content\n",
        "\n",
        "  # set file name\n",
        "  if names[index] is not None:\n",
        "    filename = names[index]+'.html'\n",
        "\n",
        "    # create new file with the hyperlink and add to folder\n",
        "    path = os.path.join(foldername, filename)\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(webpage)\n",
        "\n",
        "  index+=1\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
